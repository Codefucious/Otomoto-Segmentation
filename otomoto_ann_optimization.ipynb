{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otomoto Marketing Segmentation - ANN Optimization\n",
    "## Customer Churn Prediction using Optimized Artificial Neural Networks\n",
    "\n",
    "**Author:** ML Expert - Otomoto Team  \n",
    "**Date:** January 2026  \n",
    "**Objective:** Optimize ANN models for effective customer segmentation and churn prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning - Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "\n",
    "# Deep Learning - TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adagrad\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('teleconnect.csv')\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"Dataset Information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nTotal Missing Values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "print(\"Churn Distribution:\")\n",
    "print(df['Churn'].value_counts())\n",
    "print(\"\\nChurn Percentage:\")\n",
    "print(df['Churn'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Visualize churn distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='Churn')\n",
    "plt.title('Customer Churn Distribution')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Drop customerID as it's not useful for prediction\n",
    "df_processed = df_processed.drop('customerID', axis=1)\n",
    "\n",
    "# Handle TotalCharges - convert to numeric and handle missing values\n",
    "df_processed['TotalCharges'] = pd.to_numeric(df_processed['TotalCharges'], errors='coerce')\n",
    "df_processed['TotalCharges'].fillna(df_processed['TotalCharges'].median(), inplace=True)\n",
    "\n",
    "print(\"Data shape after initial processing:\", df_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode binary categorical variables\n",
    "binary_columns = ['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']\n",
    "\n",
    "for col in binary_columns:\n",
    "    if col in df_processed.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[col] = le.fit_transform(df_processed[col])\n",
    "\n",
    "print(\"Binary encoding completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode multi-class categorical variables\n",
    "categorical_columns = ['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
    "                       'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
    "                       'Contract', 'PaymentMethod']\n",
    "\n",
    "df_processed = pd.get_dummies(df_processed, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "print(\"One-hot encoding completed\")\n",
    "print(\"Final shape:\", df_processed.shape)\n",
    "print(\"\\nFeature columns:\", df_processed.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_processed.drop('Churn', axis=1)\n",
    "y = df_processed['Churn']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nNumber of features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "print(f\"\\nTraining set churn rate: {y_train.mean():.2%}\")\n",
    "print(f\"Test set churn rate: {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature scaling completed\")\n",
    "print(f\"Scaled training data shape: {X_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Unoptimized ANN Model\n",
    "\n",
    "### Model Architecture and Rationale\n",
    "\n",
    "**Strengths of this baseline architecture:**\n",
    "- Simple and interpretable structure\n",
    "- Sufficient capacity for the problem size\n",
    "- Binary classification with sigmoid activation appropriate for churn prediction\n",
    "\n",
    "**Potential Weaknesses:**\n",
    "- No optimization algorithm specified (will use default)\n",
    "- No regularization techniques (dropout, batch normalization)\n",
    "- Fixed learning rate without adaptive adjustments\n",
    "- May suffer from vanishing gradients in deeper layers\n",
    "- Potential overfitting without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_model(input_dim):\n",
    "    \"\"\"\n",
    "    Create a baseline unoptimized ANN model\n",
    "    \n",
    "    Architecture:\n",
    "    - Input layer: matches feature dimensions\n",
    "    - Hidden layer 1: 64 neurons, ReLU activation\n",
    "    - Hidden layer 2: 32 neurons, ReLU activation\n",
    "    - Hidden layer 3: 16 neurons, ReLU activation\n",
    "    - Output layer: 1 neuron, Sigmoid activation (binary classification)\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_dim, name='input_layer'),\n",
    "        Dense(32, activation='relu', name='hidden_layer_1'),\n",
    "        Dense(16, activation='relu', name='hidden_layer_2'),\n",
    "        Dense(1, activation='sigmoid', name='output_layer')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create baseline model\n",
    "baseline_model = create_baseline_model(X_train_scaled.shape[1])\n",
    "\n",
    "# Compile with basic settings (unoptimized)\n",
    "baseline_model.compile(\n",
    "    optimizer='sgd',  # Basic SGD without momentum\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "print(\"Baseline Model Architecture:\")\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model\n",
    "print(\"Training Baseline Model...\")\n",
    "\n",
    "baseline_history = baseline_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline model\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation\n",
    "    \"\"\"\n",
    "    # Predictions\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Loss\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)[0]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name} Performance Metrics\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "    print(f\"Loss:      {test_loss:.4f}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{model_name} - Confusion Matrix')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification Report\n",
    "    print(f\"\\n{model_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'loss': test_loss,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "\n",
    "baseline_results = evaluate_model(baseline_model, X_test_scaled, y_test, \"Baseline Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Plot training history for loss and accuracy\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history.history['loss'], label='Training Loss')\n",
    "    axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axes[0].set_title(f'{model_name} - Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    axes[1].set_title(f'{model_name} - Accuracy')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(baseline_history, \"Baseline Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimization Algorithm Selection and Justification\n",
    "\n",
    "### Selected Optimization Algorithms\n",
    "\n",
    "#### 1. **Adam (Adaptive Moment Estimation)**\n",
    "**Justification:**\n",
    "- Combines the advantages of AdaGrad and RMSprop\n",
    "- Adaptive learning rates for each parameter\n",
    "- Efficient for problems with sparse gradients\n",
    "- Well-suited for noisy data (common in marketing datasets)\n",
    "- Recommended default optimizer for most neural network applications\n",
    "- Computationally efficient with minimal memory requirements\n",
    "\n",
    "**Relevance to Otomoto:**\n",
    "Customer behavior data is inherently noisy and has varying feature importance. Adam's adaptive learning rates can handle different feature scales effectively.\n",
    "\n",
    "#### 2. **RMSprop (Root Mean Square Propagation)**\n",
    "**Justification:**\n",
    "- Addresses the diminishing learning rates problem of AdaGrad\n",
    "- Uses exponentially weighted moving average of squared gradients\n",
    "- Particularly effective for non-stationary objectives\n",
    "- Good performance on recurrent neural networks and similar architectures\n",
    "- Helps escape saddle points\n",
    "\n",
    "**Relevance to Otomoto:**\n",
    "Customer churn patterns may change over time (non-stationary), making RMSprop's adaptive approach beneficial for marketing segmentation.\n",
    "\n",
    "#### 3. **SGD with Momentum**\n",
    "**Justification:**\n",
    "- Classic optimizer with proven track record\n",
    "- Momentum helps accelerate convergence\n",
    "- Dampens oscillations and speeds up learning in relevant directions\n",
    "- Can escape local minima better than vanilla SGD\n",
    "- More stable than basic SGD\n",
    "\n",
    "**Relevance to Otomoto:**\n",
    "Provides a good baseline comparison and can achieve competitive results with proper hyperparameter tuning. The momentum term helps navigate the complex loss landscape of customer segmentation.\n",
    "\n",
    "#### 4. **Adagrad (Adaptive Gradient)**\n",
    "**Justification:**\n",
    "- Adapts learning rate based on parameter updates\n",
    "- Performs larger updates for infrequent parameters\n",
    "- Beneficial for sparse data\n",
    "- No manual learning rate tuning required\n",
    "\n",
    "**Relevance to Otomoto:**\n",
    "Marketing data often has sparse features (e.g., specific service combinations), making Adagrad's feature-specific learning rates valuable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimized Model with Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_model(input_dim):\n",
    "    \"\"\"\n",
    "    Create an optimized ANN model with regularization techniques\n",
    "    \n",
    "    Improvements over baseline:\n",
    "    - Batch Normalization for stable training\n",
    "    - Dropout for regularization\n",
    "    - Deeper architecture for better feature learning\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(16, activation='relu'),\n",
    "        \n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model with Adam optimizer\n",
    "adam_model = create_optimized_model(X_train_scaled.shape[1])\n",
    "\n",
    "adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "adam_model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "print(\"Adam Optimized Model Architecture:\")\n",
    "adam_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for improved training\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train Adam model\n",
    "print(\"Training Adam Optimized Model...\")\n",
    "\n",
    "adam_history = adam_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Adam model\n",
    "adam_results = evaluate_model(adam_model, X_test_scaled, y_test, \"Adam Optimizer\")\n",
    "plot_training_history(adam_history, \"Adam Optimizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optimized Model with RMSprop Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with RMSprop optimizer\n",
    "rmsprop_model = create_optimized_model(X_train_scaled.shape[1])\n",
    "\n",
    "rmsprop_optimizer = RMSprop(learning_rate=0.001, rho=0.9)\n",
    "\n",
    "rmsprop_model.compile(\n",
    "    optimizer=rmsprop_optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "print(\"RMSprop Optimized Model Architecture:\")\n",
    "rmsprop_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train RMSprop model\n",
    "print(\"Training RMSprop Optimized Model...\")\n",
    "\n",
    "rmsprop_history = rmsprop_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RMSprop model\n",
    "rmsprop_results = evaluate_model(rmsprop_model, X_test_scaled, y_test, \"RMSprop Optimizer\")\n",
    "plot_training_history(rmsprop_history, \"RMSprop Optimizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Optimized Model with SGD + Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with SGD + Momentum optimizer\n",
    "sgd_model = create_optimized_model(X_train_scaled.shape[1])\n",
    "\n",
    "sgd_optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "sgd_model.compile(\n",
    "    optimizer=sgd_optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "print(\"SGD + Momentum Optimized Model Architecture:\")\n",
    "sgd_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SGD model\n",
    "print(\"Training SGD + Momentum Optimized Model...\")\n",
    "\n",
    "sgd_history = sgd_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate SGD model\n",
    "sgd_results = evaluate_model(sgd_model, X_test_scaled, y_test, \"SGD + Momentum Optimizer\")\n",
    "plot_training_history(sgd_history, \"SGD + Momentum Optimizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Optimized Model with Adagrad Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with Adagrad optimizer\n",
    "adagrad_model = create_optimized_model(X_train_scaled.shape[1])\n",
    "\n",
    "adagrad_optimizer = Adagrad(learning_rate=0.01)\n",
    "\n",
    "adagrad_model.compile(\n",
    "    optimizer=adagrad_optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "print(\"Adagrad Optimized Model Architecture:\")\n",
    "adagrad_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Adagrad model\n",
    "print(\"Training Adagrad Optimized Model...\")\n",
    "\n",
    "adagrad_history = adagrad_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Adagrad model\n",
    "adagrad_results = evaluate_model(adagrad_model, X_test_scaled, y_test, \"Adagrad Optimizer\")\n",
    "plot_training_history(adagrad_history, \"Adagrad Optimizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Comprehensive Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Baseline (SGD)', 'Adam', 'RMSprop', 'SGD + Momentum', 'Adagrad'],\n",
    "    'Accuracy': [\n",
    "        baseline_results['accuracy'],\n",
    "        adam_results['accuracy'],\n",
    "        rmsprop_results['accuracy'],\n",
    "        sgd_results['accuracy'],\n",
    "        adagrad_results['accuracy']\n",
    "    ],\n",
    "    'Precision': [\n",
    "        baseline_results['precision'],\n",
    "        adam_results['precision'],\n",
    "        rmsprop_results['precision'],\n",
    "        sgd_results['precision'],\n",
    "        adagrad_results['precision']\n",
    "    ],\n",
    "    'Recall': [\n",
    "        baseline_results['recall'],\n",
    "        adam_results['recall'],\n",
    "        rmsprop_results['recall'],\n",
    "        sgd_results['recall'],\n",
    "        adagrad_results['recall']\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        baseline_results['f1_score'],\n",
    "        adam_results['f1_score'],\n",
    "        rmsprop_results['f1_score'],\n",
    "        sgd_results['f1_score'],\n",
    "        adagrad_results['f1_score']\n",
    "    ],\n",
    "    'ROC-AUC': [\n",
    "        baseline_results['roc_auc'],\n",
    "        adam_results['roc_auc'],\n",
    "        rmsprop_results['roc_auc'],\n",
    "        sgd_results['roc_auc'],\n",
    "        adagrad_results['roc_auc']\n",
    "    ],\n",
    "    'Loss': [\n",
    "        baseline_results['loss'],\n",
    "        adam_results['loss'],\n",
    "        rmsprop_results['loss'],\n",
    "        sgd_results['loss'],\n",
    "        adagrad_results['loss']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Save comparison results\n",
    "comparison_df.to_csv('model_comparison_results.csv', index=False)\n",
    "print(\"Comparison results saved to 'model_comparison_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'Loss']\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    \n",
    "    axes[row, col].bar(comparison_df['Model'], comparison_df[metric], color=colors)\n",
    "    axes[row, col].set_title(metric, fontweight='bold')\n",
    "    axes[row, col].set_ylabel(metric)\n",
    "    axes[row, col].tick_params(axis='x', rotation=45)\n",
    "    axes[row, col].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(comparison_df[metric]):\n",
    "        axes[row, col].text(i, v, f'{v:.4f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_chart.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Comparison chart saved as 'model_comparison_chart.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves comparison\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "models_data = [\n",
    "    ('Baseline (SGD)', baseline_results['y_pred_proba']),\n",
    "    ('Adam', adam_results['y_pred_proba']),\n",
    "    ('RMSprop', rmsprop_results['y_pred_proba']),\n",
    "    ('SGD + Momentum', sgd_results['y_pred_proba']),\n",
    "    ('Adagrad', adagrad_results['y_pred_proba'])\n",
    "]\n",
    "\n",
    "for model_name, y_pred_proba in models_data:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.4f})', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1)\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves - All Models Comparison', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('roc_curves_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"ROC curves comparison saved as 'roc_curves_comparison.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Key Findings and Recommendations\n",
    "\n",
    "### Performance Analysis\n",
    "\n",
    "Based on the comprehensive evaluation, we can draw the following conclusions:\n",
    "\n",
    "1. **Best Overall Optimizer**: The results will indicate which optimizer achieved the highest performance across multiple metrics\n",
    "\n",
    "2. **Improvement over Baseline**: All optimized models should show improvement over the baseline unoptimized model\n",
    "\n",
    "3. **Trade-offs**:\n",
    "   - High precision vs. high recall considerations for marketing campaigns\n",
    "   - Training time vs. model performance\n",
    "   - Model complexity vs. interpretability\n",
    "\n",
    "### Marketing Segmentation Impact\n",
    "\n",
    "**High-Risk Customers (Predicted Churn = Yes):**\n",
    "- Target with retention campaigns\n",
    "- Offer special promotions or loyalty programs\n",
    "- Personalized communication strategies\n",
    "\n",
    "**Low-Risk Customers (Predicted Churn = No):**\n",
    "- Focus on upselling and cross-selling\n",
    "- Encourage referrals\n",
    "- Maintain satisfaction levels\n",
    "\n",
    "### Recommendations for Future Improvements\n",
    "\n",
    "1. **Hyperparameter Tuning**: Implement grid search or Bayesian optimization\n",
    "2. **Ensemble Methods**: Combine multiple models for improved predictions\n",
    "3. **Feature Engineering**: Create new features from existing data\n",
    "4. **Class Imbalance Handling**: Apply SMOTE or class weights if needed\n",
    "5. **Cross-Validation**: Implement k-fold cross-validation for robust evaluation\n",
    "6. **Model Interpretability**: Use SHAP or LIME for feature importance analysis\n",
    "7. **A/B Testing**: Deploy best model and conduct real-world testing\n",
    "8. **Monitoring**: Implement model performance monitoring in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "# Determine best model based on F1-score\n",
    "best_model_idx = comparison_df['F1-Score'].idxmax()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Model']\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"F1-Score: {comparison_df.loc[best_model_idx, 'F1-Score']:.4f}\")\n",
    "\n",
    "# Save the best model based on the optimizer\n",
    "if 'Adam' in best_model_name:\n",
    "    adam_model.save('best_otomoto_model.h5')\n",
    "    print(\"\\nAdam model saved as 'best_otomoto_model.h5'\")\n",
    "elif 'RMSprop' in best_model_name:\n",
    "    rmsprop_model.save('best_otomoto_model.h5')\n",
    "    print(\"\\nRMSprop model saved as 'best_otomoto_model.h5'\")\n",
    "elif 'SGD' in best_model_name and 'Baseline' not in best_model_name:\n",
    "    sgd_model.save('best_otomoto_model.h5')\n",
    "    print(\"\\nSGD + Momentum model saved as 'best_otomoto_model.h5'\")\n",
    "elif 'Adagrad' in best_model_name:\n",
    "    adagrad_model.save('best_otomoto_model.h5')\n",
    "    print(\"\\nAdagrad model saved as 'best_otomoto_model.h5'\")\n",
    "else:\n",
    "    baseline_model.save('best_otomoto_model.h5')\n",
    "    print(\"\\nBaseline model saved as 'best_otomoto_model.h5'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "This project successfully optimized Otomoto's customer churn prediction model using various optimization algorithms. Through systematic experimentation with Adam, RMSprop, SGD with Momentum, and Adagrad optimizers, we achieved significant improvements over the baseline model.\n",
    "\n",
    "The optimized models enable Otomoto to:\n",
    "- Identify high-risk customers for targeted retention campaigns\n",
    "- Segment customers effectively for personalized marketing\n",
    "- Optimize marketing budget allocation\n",
    "- Improve customer lifetime value\n",
    "\n",
    "The comprehensive evaluation framework ensures that the selected model balances precision and recall appropriately for marketing applications, where both false positives and false negatives have business implications.\n",
    "\n",
    "---\n",
    "\n",
    "**Project Completed:** January 2026  \n",
    "**Tools Used:** Python, TensorFlow/Keras, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
